{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[11] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# start spark with 4 worker threads (since 4 cores available)\n",
    "sc = SparkContext(\"local[4]\")\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "# read the input files into an RDD[String] and split each line into an array of items\n",
    "# 1 file of machine events (~ 3 MB)\n",
    "# first 200 files of job events (~ 128 MB)\n",
    "# first 7 files of task events (~ 137 MB)\n",
    "# first file of task usage (~ 364 MB)\n",
    "machine_events_file = sc.textFile(\"data/machine_events/part-00000-of-00001.csv\").map(lambda x : x.split(','))\n",
    "job_events_file = sc.textFile(\"data/job_events/part-00[0-1][0-9][0-9]-of-00500.csv\").map(lambda x : x.split(','))\n",
    "task_events_file = sc.textFile(\"data/task_events/part-0000[0-6]-of-00500.csv\").map(lambda x : x.split(','))\n",
    "task_usage_file = sc.textFile(\"data/task_usage/part-00001-of-00500.csv\").map(lambda x : x.split(','))\n",
    "\n",
    "# keep the RDD in memory\n",
    "machine_events_file.cache()\n",
    "job_events_file.cache()\n",
    "task_events_file.cache()\n",
    "task_usage_file.cache()\n",
    "\n",
    "# show the number of observations (lines)\n",
    "# print(machine_events_file.count())\n",
    "# print(job_events_file.count())\n",
    "# print(task_events_file.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: What is the distribution of the machines according to their CPU capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare indexes (machine ID and CPU) according to \"schema.csv\" file\n",
    "i_mID = 1\n",
    "i_CPU = 4\n",
    "\n",
    "# create (machine_ID, CPU) unique pairs\n",
    "mID_CPU = machine_events_file.map(lambda x: (x[i_mID], x[i_CPU])).distinct()\n",
    "\n",
    "# TODO: create graph (or other illustr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: What is the percentage of computational power lost due to maintenance (a machine went offline and reconnected later)?\n",
    "\n",
    "TODO: Challenges: Thinking in key-value paradigm. How result should look like? Tried (time, % lost), but % always 0 or 100. Couldn't convert to float, because some CPU not given.\n",
    "\n",
    "Conclusion: More memory capacity loss than cpu power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of computational power lost due to maintenance: 23.99 %\n",
      "Percentage of memory capacity lost due to maintenance: 24.47 %\n"
     ]
    }
   ],
   "source": [
    "## formula: (lost CPU power / total CPU power) * 100 \n",
    "\n",
    "# get total CPU power\n",
    "col_CPU = machine_events_file.map(lambda x: x[4])  # get only CPU column\n",
    "col_CPU = col_CPU.filter(lambda x: len(x) > 0)     # filter rows with no CPU data \n",
    "col_CPU = col_CPU.map(lambda x: float(x))          # convert CPU to float\n",
    "total_CPU = col_CPU.sum()                          # sum up column\n",
    "\n",
    "# get total lost CPU power (event_type == 1)\n",
    "col_CPU_lost = machine_events_file.map(lambda x: (x[4], x[2])).filter(lambda x: x[1] == '1')\n",
    "col_CPU_lost = col_CPU_lost.filter(lambda x: len(x[0]) > 0).map(lambda x: float(x[0]))\n",
    "total_lost_CPU = col_CPU_lost.sum()\n",
    "\n",
    "# result\n",
    "print(\"Percentage of computational power lost due to maintenance:\", \n",
    "      round((total_lost_CPU / total_CPU) * 100, 2), \"%\")\n",
    "\n",
    "# same for % of memory capacity lost\n",
    "total_mem = machine_events_file.map(lambda x: x[5]).filter(lambda x: len(x) > 0).map(lambda x: float(x)).sum()\n",
    "total_lost_mem = machine_events_file.map(lambda x: (x[5], x[2])).filter(lambda x: x[1] == '1' and len(x[0]) > 0).map(lambda x: float(x[0])).sum()\n",
    "\n",
    "print(\"Percentage of memory capacity lost due to maintenance:\", \n",
    "      round((total_lost_mem / total_mem) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: What is the distribution of the number jobs/tasks per scheduling class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 257814), ('0', 305793), ('2', 211509), ('3', 7705)]\n",
      "[('1', 155637), ('0', 805914), ('3', 60468), ('2', 218972)]\n"
     ]
    }
   ],
   "source": [
    "## Goal:\n",
    "# (sch_class, nb_jobs) pairs\n",
    "# (sch_class, nb_tasks) pairs\n",
    "\n",
    "# index of scheduling class is 5 at job_events_file and 7 at task_events_file\n",
    "# create (sch_class, 1) tuple\n",
    "# and reduce by sch_class, summing up values\n",
    "jobs_per_class =   job_events_file.map(lambda x: (x[5], 1)).reduceByKey(lambda x,y: x+y)\n",
    "tasks_per_class = task_events_file.map(lambda x: (x[7], 1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# show results\n",
    "print(jobs_per_class.collect())\n",
    "print(tasks_per_class.collect())\n",
    "\n",
    "# TODO: bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: What is the percentage of jobs/tasks that got killed or evicted depending on the scheduling class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', 0.0032701860408838658, 17.661620769605584)\n",
      "('1', 0.0015515061245704267, 6.230460719743691)\n",
      "('2', 0.0, 14.667933752228038)\n",
      "('3', 0.0, 24.87994808565866)\n",
      "('0', 4.828058576969751, 5.942569554567857)\n",
      "('1', 5.226906198397553, 1.477155175183279)\n",
      "('2', 2.8410025026030725, 16.00798275578613)\n",
      "('3', 0.3274459218098829, 2.39630879142687)\n"
     ]
    }
   ],
   "source": [
    "## Goal:\n",
    "# (sch_class, %_jobs_evicted, %_jobs_killed)\n",
    "# (sch_class, %_tasks_evicted, %_tasks_killed)\n",
    "\n",
    "# for event_type, 2 means EVICT, 5 means KILL\n",
    "# event_type index is 3 at job_events and 5 at task_events\n",
    "\n",
    "# create (sch_class, 1) pairs, for jobs and tasks, for event_type 2 and 5\n",
    "jobs_evict = job_events_file.filter(lambda x: x[3] == '2').map(lambda x: (x[5], 1))\n",
    "jobs_kill  = job_events_file.filter(lambda x: x[3] == '5').map(lambda x: (x[5], 1))\n",
    "tasks_evict = task_events_file.filter(lambda x: x[5] == '2').map(lambda x: (x[7], 1))\n",
    "tasks_kill  = task_events_file.filter(lambda x: x[5] == '5').map(lambda x: (x[7], 1))\n",
    "\n",
    "# reduce by sch_class, summing up values, and tranform to dictionary\n",
    "jobs_evict_per_class   = jobs_evict.reduceByKey(lambda x,y: x+y).collectAsMap()\n",
    "jobs_kill_per_class     = jobs_kill.reduceByKey(lambda x,y: x+y).collectAsMap()\n",
    "tasks_evict_per_class = tasks_evict.reduceByKey(lambda x,y: x+y).collectAsMap()\n",
    "tasks_kill_per_class   = tasks_kill.reduceByKey(lambda x,y: x+y).collectAsMap()\n",
    "\n",
    "# total nb of events per class\n",
    "job_events_per_class = job_events_file.map(lambda x: (x[5], 1)).reduceByKey(lambda x,y: x+y)\n",
    "task_events_per_class = task_events_file.map(lambda x: (x[7], 1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# (sch_class, %_evict) and (sch_class, %_kill)\n",
    "job_percent_evict_per_class = job_events_per_class.map(lambda x: (x[0], (jobs_evict_per_class[x[0]] / x[1])*100 \n",
    "                                                                          if x[0] in jobs_evict_per_class\n",
    "                                                                          else 0.0))\n",
    "job_percent_kill_per_class  = job_events_per_class.map(lambda x: (x[0], (jobs_kill_per_class[x[0]] / x[1])*100 \n",
    "                                                                          if x[0] in jobs_kill_per_class\n",
    "                                                                          else 0.0))\n",
    "task_percent_evict_per_class = task_events_per_class.map(lambda x: (x[0], (tasks_evict_per_class[x[0]] / x[1])*100 \n",
    "                                                                          if x[0] in tasks_evict_per_class\n",
    "                                                                          else 0.0))\n",
    "task_percent_kill_per_class  = task_events_per_class.map(lambda x: (x[0], (tasks_kill_per_class[x[0]] / x[1])*100 \n",
    "                                                                          if x[0] in tasks_kill_per_class\n",
    "                                                                          else 0.0))\n",
    "\n",
    "# transform to dictionary, need for merging\n",
    "job_percent_kill_per_class = job_percent_kill_per_class.collectAsMap()\n",
    "task_percent_kill_per_class = task_percent_kill_per_class.collectAsMap()\n",
    "\n",
    "# (sch_class, %_jobs_evicted, %_jobs_killed)\n",
    "res_job = job_percent_evict_per_class.map(lambda x: (x[0], x[1], job_percent_kill_per_class[x[0]]))\n",
    "# (sch_class, %_tasks_evicted, %_tasks_killed)\n",
    "res_task = task_percent_evict_per_class.map(lambda x: (x[0], x[1], task_percent_kill_per_class[x[0]]))\n",
    "\n",
    "# print results\n",
    "for f in sorted(res_job.collect()):\n",
    "    print(f)\n",
    "for f in sorted(res_task.collect()):\n",
    "    print(f)\n",
    "    \n",
    "# TODO: round(x, 4), double bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Do tasks with low priority have a higher probability of being evicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 11.12),\n",
       " ('1', 1.96),\n",
       " ('2', 0.07),\n",
       " ('8', 0.06),\n",
       " ('9', 0.15),\n",
       " ('10', 0.1),\n",
       " ('11', 0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Goal:\n",
    "# (task_priority, %_evicted) pairs\n",
    "# task_priority index is 8\n",
    "\n",
    "# create (task_priority, 1) pairs, and reduce by task_priority, summing up values\n",
    "total_by_priority = task_events_file.map(lambda x: (x[8], 1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# create (task_priority, 1) pairs, where event == EVICT, and reduce by task_priority, summing up values\n",
    "nb_evicted_by_priority = task_events_file.filter(lambda x: x[5] == '2').map(lambda x: (x[8], 1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# convert to dictionary\n",
    "nb_evicted_by_priority = nb_evicted_by_priority.collectAsMap()\n",
    "\n",
    "res = total_by_priority.map(lambda x: (x[0], round((nb_evicted_by_priority[x[0]] / x[1])*100, 2) \n",
    "                                               if x[0] in nb_evicted_by_priority \n",
    "                                               else 0.0))\n",
    "\n",
    "# show result\n",
    "res.sortBy(lambda x: int(x[0])).collect()\n",
    "\n",
    "# answer: tasks with low priority have a higher probability of being evicted\n",
    "\n",
    "# TODO: illustrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: In general, do tasks from the same job run on the same machine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 74.09 % of jobs, at least 50 % of tasks run on the same machine\n",
      "We can conclude that in general, tasks from the same job run on the same machine\n"
     ]
    }
   ],
   "source": [
    "## Goal: \n",
    "# tuple of 2 components: job_ID, \n",
    "#                        highest % of tasks from that job_ID running on same machine\n",
    "# if 2nd component is >= 50% in at least half of cases (job_IDs), then answer is yes\n",
    "\n",
    "# job ID index is 2, machine ID is 4\n",
    "\n",
    "# create (job_ID, list_of_machines) pair\n",
    "job_machine = task_events_file.map(lambda x: (x[2], x[4])).groupByKey().mapValues(list)\n",
    "\n",
    "# create (job_ID, highest % of tasks from that job_ID running on same machine) pair\n",
    "highest_percentage_per_job = job_machine.map(lambda x: (x[0], \n",
    "                                                        (x[1].count(max(set(x[1]), key=x[1].count))\n",
    "                                                        / len(x[1])) * 100))\n",
    "\n",
    "# keep the RDD in memory, because computation is very costly\n",
    "job_machine.cache()\n",
    "highest_percentage_per_job.cache()\n",
    "\n",
    "# total nb of jobs\n",
    "total_per_job = highest_percentage_per_job.count()\n",
    "# nb of jobs where % of tasks running on same machine is >= 50\n",
    "half_or_more_per_job = highest_percentage_per_job.filter(lambda x: x[1] >= 50.0).count()\n",
    "\n",
    "# result\n",
    "print(\"In\", round((half_or_more_per_job / total_per_job) * 100, 2), \n",
    "      \"% of jobs, at least 50 % of tasks run on the same machine\")\n",
    "print(\"We can conclude that in general, tasks from the same job run on the same machine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Are there tasks that consume significantly less resources than what they requested?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762662\n",
      "2033047\n"
     ]
    }
   ],
   "source": [
    "## Goal:\n",
    "# True if there exists a task that didn't consume at least 50 % of requested ressource (CPU, memory or disk space)\n",
    "\n",
    "# task_event columns:\n",
    "#  job ID (2), \n",
    "#  task index (3), \n",
    "#  machine ID (4), \n",
    "#  memory request (10), \n",
    "#  disk space request (11), \n",
    "#  CPU request (9)\n",
    "\n",
    "# task_usage columns:\n",
    "#  job ID (2), \n",
    "#  task index (3), \n",
    "#  machine ID (4), \n",
    "#  maximum memory usage (10), \n",
    "#  local disk space usage (12), \n",
    "#  sampled CPU usage (19)\n",
    "\n",
    "\n",
    "# create ((job_ID, task_index, machine_ID), \n",
    "#         (memory, disk_space, CPU)) nested tuple\n",
    "#\n",
    "# where (job_ID, task_index, machine_ID) is key\n",
    "#       (memory, disk_space, CPU) is value\n",
    "#\n",
    "# and filter rows where no info about resource\n",
    "requested_pow = task_events_file.map(lambda x: ((x[ 2], x[ 3], x[4]), \n",
    "                                                (x[10], x[11], x[9]))\n",
    "                                    ).filter(lambda x: len(x[1][0]) > 0 and \n",
    "                                                       len(x[1][1]) > 0 and \n",
    "                                                       len(x[1][2]) > 0\n",
    "                                            ).distinct()\n",
    "\n",
    "used_pow = task_usage_file.map(lambda x: ((x[ 2], x[ 3], x[ 4]),\n",
    "                                          (x[10], x[12], x[19]))\n",
    "                              ).filter(lambda x: len(x[1][0]) > 0 and\n",
    "                                                 len(x[1][1]) > 0 and\n",
    "                                                 len(x[1][2]) > 0\n",
    "                                      ).distinct()\n",
    "\n",
    "# keep rdd in memory\n",
    "requested_pow.cache()\n",
    "used_pow.cache()\n",
    "\n",
    "# show nb of observations\n",
    "print(requested_pow.count())\n",
    "print(used_pow.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ((job_ID, task_index, machine_ID), \n",
    "#         (memory_requested, disk_space_requested, CPU_requested),\n",
    "#         (memory_used, disk_space_used, CPU_used)) nested tuple\n",
    "# requested_pow_dict = requested_pow.collectAsMap()\n",
    "# requested_pow_dict_keys = list(requested_pow.collectAsMap().keys())\n",
    "\n",
    "# task_consumption = used_pow.filter(lambda x: x[0] in requested_pow_dict_keys)\n",
    "# task_consumption.cache()\n",
    "# task_consumption.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726051\n",
      "152340\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(requested_pow.keys().distinct().count())\n",
    "print(used_pow.keys().distinct().count())\n",
    "\n",
    "762662\n",
    "726051\n",
    "\n",
    "2033047\n",
    "152340\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: How often does it happen that the resources of a machine are over-committed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: \n",
    "# get tuple:\n",
    "#  (time_t, \n",
    "#   machine_ID\n",
    "#   [list_of_requested_ressources_at_time_t_on_machine_ID] as list1,\n",
    "#   [list_of_used_ressources_at_time_t_on_machine_ID] as list2)\n",
    "# then result is the % of list1 == list2\n",
    "# i.e. result = (tuple.filter(list1 == list2).count() / tuple.count()) * 100\n",
    "\n",
    "# Step 1\n",
    "# task_event \n",
    "# get (time (0), machine ID (4), CPU request (9) , memory request (10), disk space request (11))\n",
    "# filter 4 event types (index 5) that don't allow tasks to appear in task_usage:\n",
    "# SUBMIT, FINISH, KILL and UPDATE_PENDING\n",
    "task_event_data = task_events_file.filter(lambda x: x[5] != '0' and x[5] != '4' and x[5] != '5' and x[5] != '7')\n",
    "task_event_data = task_event_data.map(lambda x: (x[0], x[4], x[9], x[10], x[11])).distinct()\n",
    "\n",
    "# Step 2\n",
    "# task_usage \n",
    "# get:\n",
    "# (start time (0), machine ID (4), sampled CPU usage (19), maximum memory usage (10), local disk space usage (12))\n",
    "task_usage_data = task_usage_file.map(lambda x: (x[0], x[4], x[19], x[10], x[12])).distinct()\n",
    "\n",
    "# Step 3\n",
    "# we have:\n",
    "#  requested: (t, ID, CPU, RAM, disk)\n",
    "#  used:      (t, ID, CPU, RAM, disk)\n",
    "# we need:\n",
    "#  requested: ((t, ID), list of requested (CPU, RAM, disk) at t on ID)\n",
    "#  used:      ((t, ID), list of used (CPU, RAM, disk) at t on ID)\n",
    "requested = task_event_data.map(lambda x: ((x[0], x[1]), (x[2], x[3], x[4]))).groupByKey().mapValues(list)\n",
    "used = task_usage_data.map(lambda x: ((x[0], x[1]), (x[2], x[3], x[4]))).groupByKey().mapValues(list)\n",
    "\n",
    "# keep rdd in memory\n",
    "requested.cache()\n",
    "used.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4\n",
    "# get:\n",
    "#  ( (time_t, \n",
    "#     machine_ID),\n",
    "#    ([list_of_requested_ressources_at_time_t_on_machine_ID],\n",
    "#     [list_of_used_ressources_at_t_on_machine_ID]))\n",
    "\n",
    "\n",
    "# Step 5\n",
    "# show % of overcommitting for the first result.count() observations\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
